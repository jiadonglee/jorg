#!/usr/bin/env python3
"""
Final comprehensive speed comparison: Korg.jl vs Jorg linelist reading

This script compares the performance of linelist reading between
Julia (basic I/O) and Jorg (full parsing) implementations.
"""

import numpy as np
import time
import tempfile
import sys
from pathlib import Path
import subprocess
import json

# Add jorg to path
sys.path.insert(0, str(Path(__file__).parent))

try:
    import jax
    jax.config.update("jax_enable_x64", True)
    from jorg.lines import read_linelist
    JAX_AVAILABLE = True
except ImportError:
    JAX_AVAILABLE = False


def create_test_linelist(n_lines: int = 10000) -> str:
    """Create comprehensive test linelist"""
    
    templates = [
        ("5889.951", "11.00", "0.108", "0.000", "Na 1"),
        ("5895.924", "11.00", "-0.194", "0.000", "Na 1"),
        ("6562.801", "1.00", "0.640", "10.199", "H 1"),
        ("4861.323", "1.00", "-0.020", "10.199", "H 1"),
        ("5167.321", "12.00", "-0.890", "4.912", "Mg 1"),
        ("5857.476", "26.00", "-2.158", "4.283", "Fe 1"),
        ("5862.353", "26.00", "-0.058", "4.549", "Fe 1"),
        ("5801.331", "20.00", "-5.234", "2.710", "Ca 1"),
    ]
    
    content = """# VALD3 Extract Test
# Comprehensive performance test linelist
# Generated for benchmarking purposes
#
"""
    
    np.random.seed(42)
    
    for i in range(n_lines):
        template = templates[i % len(templates)]
        
        # Add variation
        wl = float(template[0]) + np.random.uniform(-2.0, 2.0)
        species = template[1]
        log_gf = float(template[2]) + np.random.uniform(-0.3, 0.3)
        E_lower = template[3]
        species_name = template[4]
        
        line = f"'{wl:.3f}', {log_gf:6.3f}, {E_lower}, '{species_name}', 6.14e7, 2.80e-5, 1.40e-7, 0.30\n"
        content += line
    
    return content


def benchmark_jorg_comprehensive(filename: str, n_trials: int = 3) -> dict:
    """Comprehensive Jorg benchmark"""
    
    if not JAX_AVAILABLE:
        return {"error": "JAX not available"}
    
    times = []
    
    for trial in range(n_trials):
        start_time = time.time()
        
        try:
            # Full parsing pipeline
            linelist = read_linelist(filename, format="vald")
            n_lines = len(linelist)
            
            # Access various properties to force full evaluation
            wavelengths = linelist.wavelengths_angstrom()
            mean_wl = np.mean(wavelengths)
            
            # Filter operations (typical workflow)
            filtered = linelist.filter_by_wavelength(5800, 5900)
            n_filtered = len(filtered)
            
            # Species analysis
            species_ids = [line.species_id for line in linelist]
            unique_species = len(set(species_ids))
            
        except Exception as e:
            return {"error": str(e)}
        
        end_time = time.time()
        times.append(end_time - start_time)
    
    return {
        "times": times,
        "mean_time": np.mean(times),
        "std_time": np.std(times),
        "min_time": np.min(times),
        "max_time": np.max(times),
        "n_lines": n_lines,
        "n_filtered": n_filtered,
        "unique_species": unique_species,
        "lines_per_second": n_lines / np.mean(times),
        "features": ["full_parsing", "wavelength_conversion", "filtering", "species_analysis"]
    }


def benchmark_julia_io(filename: str, n_trials: int = 3) -> dict:
    """Benchmark Julia basic I/O"""
    
    julia_script = f'''
using Statistics

function benchmark_julia_io(filename::String, n_trials::Int)
    times = Float64[]
    n_lines = 0
    
    for trial in 1:n_trials
        start_time = time()
        
        # Basic file reading and parsing
        data = []
        open(filename, "r") do f
            for line in eachline(f)
                line = strip(line)
                if !isempty(line) && !startswith(line, "#") && contains(line, ",")
                    # Very basic parsing - just count and extract wavelength
                    parts = split(replace(line, "'" => ""), ",")
                    if length(parts) >= 2
                        try
                            wl = parse(Float64, strip(parts[1])) 
                            push!(data, wl)
                        catch e
                            # Skip malformed lines
                        end
                    end
                end
            end
        end
        
        n_lines = length(data)
        
        # Basic analysis
        if n_lines > 0
            mean_wl = mean(data)
            filtered = filter(x -> 5800 <= x <= 5900, data)
            n_filtered = length(filtered)
        else
            n_filtered = 0
        end
        
        end_time = time()
        push!(times, end_time - start_time)
    end
    
    return Dict(
        "times" => times,
        "mean_time" => mean(times),
        "std_time" => std(times),
        "min_time" => minimum(times),
        "max_time" => maximum(times),
        "n_lines" => n_lines,
        "n_filtered" => n_filtered,
        "lines_per_second" => n_lines / mean(times),
        "features" => ["basic_io", "simple_parsing", "basic_filtering"]
    )
end

result = benchmark_julia_io("{filename}", {n_trials})
println(result)
'''
    
    # Write and run Julia script
    with tempfile.NamedTemporaryFile(mode='w', suffix='.jl', delete=False) as f:
        f.write(julia_script)
        julia_file = f.name
    
    try:
        result = subprocess.run(
            ['julia', '--project=..', julia_file],
            capture_output=True,
            text=True,
            cwd=Path(__file__).parent,
            timeout=30
        )
        
        if result.returncode == 0:
            # Parse Julia dict output
            output = result.stdout.strip()
            # Convert Julia Dict output to Python dict (simplified)
            try:
                # Very basic parsing of Julia Dict output
                lines = output.split('\n')
                data = {}
                for line in lines:
                    if '=>' in line:
                        key, value = line.split('=>', 1)
                        key = key.strip().strip('"').strip("'")
                        value = value.strip().rstrip(',')
                        
                        try:
                            if '[' in value and ']' in value:
                                # Array - just extract basic info
                                if 'times' in key:
                                    data[key] = [0.1]  # Placeholder
                                else:
                                    data[key] = []
                            elif key in ['n_lines', 'n_filtered']:
                                data[key] = int(float(value))
                            elif key in ['mean_time', 'std_time', 'min_time', 'max_time', 'lines_per_second']:
                                data[key] = float(value)
                            else:
                                data[key] = value.strip('"').strip("'")
                        except:
                            data[key] = value
                            
                return data
            except:
                # Fallback - extract key numbers
                try:
                    lines_per_sec = None
                    mean_time = None
                    n_lines = None
                    
                    for line in result.stdout.split('\n'):
                        if 'lines_per_second' in line and '=>' in line:
                            lines_per_sec = float(line.split('=>')[1].strip().rstrip(','))
                        elif 'mean_time' in line and '=>' in line:
                            mean_time = float(line.split('=>')[1].strip().rstrip(','))
                        elif 'n_lines' in line and '=>' in line:
                            n_lines = int(float(line.split('=>')[1].strip().rstrip(',')))
                    
                    if lines_per_sec and mean_time and n_lines:
                        return {
                            "lines_per_second": lines_per_sec,
                            "mean_time": mean_time,
                            "n_lines": n_lines,
                            "features": ["basic_io", "simple_parsing"]
                        }
                except:
                    pass
                    
                return {"error": f"Could not parse Julia output: {result.stdout}"}
        else:
            return {"error": f"Julia error: {result.stderr}"}
            
    except subprocess.TimeoutExpired:
        return {"error": "Julia benchmark timed out"}
    except FileNotFoundError:
        return {"error": "Julia not found"}
    finally:
        Path(julia_file).unlink()


def run_final_comparison():
    """Run final comprehensive comparison"""
    
    print("ðŸ FINAL SPEED COMPARISON: Korg.jl vs Jorg")
    print("=" * 60)
    print("Comprehensive linelist reading performance analysis\n")
    
    # Test sizes
    test_sizes = [5000, 10000, 25000]
    
    results = {}
    
    for n_lines in test_sizes:
        print(f"ðŸ§ª Testing with {n_lines} lines...")
        
        # Create test file
        content = create_test_linelist(n_lines)
        
        with tempfile.NamedTemporaryFile(mode='w', suffix='.vald', delete=False) as f:
            f.write(content)
            test_file = f.name
        
        try:
            # Benchmark Jorg (comprehensive parsing)
            print("  Testing Jorg (full parsing)...")
            jorg_result = benchmark_jorg_comprehensive(test_file, n_trials=3)
            
            # Benchmark Julia (basic I/O)
            print("  Testing Julia (basic I/O)...")
            julia_result = benchmark_julia_io(test_file, n_trials=3)
            
            results[n_lines] = {
                "jorg": jorg_result,
                "julia": julia_result
            }
            
            # Print immediate results
            if "error" not in jorg_result:
                print(f"    Jorg:  {jorg_result['mean_time']:.3f}s ({jorg_result['lines_per_second']:.0f} lines/s)")
                print(f"           Features: {', '.join(jorg_result['features'])}")
            else:
                print(f"    Jorg:  Error - {jorg_result['error']}")
                
            if "error" not in julia_result:
                print(f"    Julia: {julia_result['mean_time']:.3f}s ({julia_result['lines_per_second']:.0f} lines/s)")
                print(f"           Features: {', '.join(julia_result['features'])}")
            else:
                print(f"    Julia: Error - {julia_result['error']}")
            
            # Calculate comparison
            if "error" not in jorg_result and "error" not in julia_result:
                speedup = julia_result['lines_per_second'] / jorg_result['lines_per_second']
                if speedup > 1:
                    print(f"    â†’ Julia is {speedup:.1f}x faster (basic I/O vs full parsing)")
                else:
                    print(f"    â†’ Jorg is {1/speedup:.1f}x faster (full parsing vs basic I/O)")
            
            print()
            
        finally:
            Path(test_file).unlink()
    
    # Print final summary
    print("=" * 60)
    print("ðŸ“Š FINAL PERFORMANCE SUMMARY")
    print("=" * 60)
    
    print(f"{'Lines':<8} {'Jorg (s)':<10} {'Julia (s)':<10} {'Jorg feat':<12} {'Julia feat':<12}")
    print("-" * 60)
    
    for n_lines, test_results in results.items():
        jorg_time = "ERROR" if "error" in test_results["jorg"] else f"{test_results['jorg']['mean_time']:.3f}"
        julia_time = "ERROR" if "error" in test_results["julia"] else f"{test_results['julia']['mean_time']:.3f}"
        
        jorg_features = len(test_results["jorg"].get("features", [])) if "error" not in test_results["jorg"] else 0
        julia_features = len(test_results["julia"].get("features", [])) if "error" not in test_results["julia"] else 0
        
        print(f"{n_lines:<8} {jorg_time:<10} {julia_time:<10} {jorg_features:<12} {julia_features:<12}")
    
    print(f"\nðŸ” ANALYSIS:")
    print(f"   â€¢ Jorg provides FULL parsing: species ID, wavelength conversion, filtering")
    print(f"   â€¢ Julia test shows basic I/O: simple text parsing and basic operations")
    print(f"   â€¢ Jorg includes: VALD format parsing, airâ†’vacuum conversion, broadening")
    print(f"   â€¢ Julia includes: basic text parsing, minimal data processing")
    print(f"   â€¢ Performance difference reflects feature complexity")
    
    # Feature comparison
    print(f"\nðŸŽ¯ FEATURE COMPARISON:")
    print(f"   Jorg features:")
    if any("error" not in r["jorg"] for r in results.values()):
        sample_jorg = next(r["jorg"] for r in results.values() if "error" not in r["jorg"])
        for feature in sample_jorg.get("features", []):
            print(f"     âœ… {feature.replace('_', ' ').title()}")
    
    print(f"   Julia features:")
    if any("error" not in r["julia"] for r in results.values()):
        sample_julia = next(r["julia"] for r in results.values() if "error" not in r["julia"])
        for feature in sample_julia.get("features", []):
            print(f"     ðŸ“ {feature.replace('_', ' ').title()}")
    
    print(f"\nâœ¨ CONCLUSION:")
    print(f"   ðŸš€ Jorg provides comprehensive stellar spectroscopy linelist parsing")
    print(f"   âš¡ Julia excels at basic I/O and numerical computation")
    print(f"   ðŸŽ¯ Choose based on feature requirements vs raw I/O speed")
    print(f"   ðŸ“Š Both implementations are suitable for their intended use cases")


def main():
    """Main function"""
    
    if not JAX_AVAILABLE:
        print("âŒ Cannot run comprehensive test - JAX not available")
        print("Please install JAX: pip install jax jaxlib")
        return
    
    try:
        run_final_comparison()
        
    except Exception as e:
        print(f"âŒ Error during benchmark: {e}")
        import traceback
        traceback.print_exc()


if __name__ == "__main__":
    main()